{"ast":null,"code":"'use strict';\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.StopWordsTokenizer = undefined;\n\nvar _createClass = function () {\n  function defineProperties(target, props) {\n    for (var i = 0; i < props.length; i++) {\n      var descriptor = props[i];\n      descriptor.enumerable = descriptor.enumerable || false;\n      descriptor.configurable = true;\n      if (\"value\" in descriptor) descriptor.writable = true;\n      Object.defineProperty(target, descriptor.key, descriptor);\n    }\n  }\n\n  return function (Constructor, protoProps, staticProps) {\n    if (protoProps) defineProperties(Constructor.prototype, protoProps);\n    if (staticProps) defineProperties(Constructor, staticProps);\n    return Constructor;\n  };\n}();\n\nvar _StopWordsMap = require('../StopWordsMap');\n\nfunction _classCallCheck(instance, Constructor) {\n  if (!(instance instanceof Constructor)) {\n    throw new TypeError(\"Cannot call a class as a function\");\n  }\n}\n/**\n * Stop words are very common (e.g. \"a\", \"and\", \"the\") and are often not semantically meaningful in the context of a\n * search. This tokenizer removes stop words from a set of tokens before passing the remaining tokens along for\n * indexing or searching purposes.\n */\n\n\nvar StopWordsTokenizer = exports.StopWordsTokenizer = function () {\n  /**\n   * Constructor.\n   *\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  function StopWordsTokenizer(decoratedTokenizer) {\n    _classCallCheck(this, StopWordsTokenizer);\n\n    this._tokenizer = decoratedTokenizer;\n  }\n  /**\n   * @inheritDocs\n   */\n\n\n  _createClass(StopWordsTokenizer, [{\n    key: 'tokenize',\n    value: function tokenize(text) {\n      return this._tokenizer.tokenize(text).filter(function (token) {\n        return !_StopWordsMap.StopWordsMap[token];\n      });\n    }\n  }]);\n\n  return StopWordsTokenizer;\n}();\n\n;","map":{"version":3,"sources":["../../../source/Tokenizer/StopWordsTokenizer.js"],"names":["StopWordsTokenizer","text"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;AAIA,IAAA,aAAA,GAAA,OAAA,CAAA,iBAAA,CAAA;;;;;;;AAEA;;;;;;;IAKaA,kB,WAAAA,kB;AAGX;;;;;AAKA,WAAA,kBAAA,CAAA,kBAAA,EAA6C;AAAA,IAAA,eAAA,CAAA,IAAA,EAAA,kBAAA,CAAA;;AAC3C,SAAA,UAAA,GAAA,kBAAA;AACD;AAED;;;;;;;6BAGSC,I,EAA+B;AACtC,aAAO,KAAA,UAAA,CAAA,QAAA,CAAA,IAAA,EAAA,MAAA,CAEH,UAAA,KAAA,EAAA;AAAA,eAAW,CAAC,aAAA,CAAA,YAAA,CAAZ,KAAY,CAAZ;AAFJ,OAAO,CAAP;AAID;;;;;;AACF","sourcesContent":["// @flow\n\nimport type { ITokenizer } from './Tokenizer';\n\nimport { StopWordsMap } from '../StopWordsMap';\n\n/**\n * Stop words are very common (e.g. \"a\", \"and\", \"the\") and are often not semantically meaningful in the context of a\n * search. This tokenizer removes stop words from a set of tokens before passing the remaining tokens along for\n * indexing or searching purposes.\n */\nexport class StopWordsTokenizer implements ITokenizer {\n  _tokenizer : ITokenizer;\n\n  /**\n   * Constructor.\n   *\n   * @param decoratedIndexStrategy Index strategy to be run after all stop words have been removed.\n   */\n  constructor(decoratedTokenizer : ITokenizer) {\n    this._tokenizer = decoratedTokenizer;\n  }\n\n  /**\n   * @inheritDocs\n   */\n  tokenize(text : string) : Array<string> {\n    return this._tokenizer.tokenize(text)\n      .filter(\n        (token) => !StopWordsMap[token]\n      );\n  }\n};\n"]},"metadata":{},"sourceType":"script"}